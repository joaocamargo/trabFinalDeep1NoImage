{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of TrabalhoDeep1_rayx.ipynb","provenance":[{"file_id":"12dcIEhQLQXl_ocGBO0XRy4u6JSXz71Ry","timestamp":1569884899649},{"file_id":"1NGBqis0ff2gUeS0HzfZnRN-r78fQfEfz","timestamp":1569760254885},{"file_id":"1cO-HdAqGlxmWc3fN24jRzTpS8sFXo_hM","timestamp":1569281225700},{"file_id":"1Sc0I9d2j-PLz3BU-RpNVUjlaNRVHkoMv","timestamp":1569154084169},{"file_id":"1x2oq7OT6Iwiyvk0q2YSaz2vXDMIOXT2p","timestamp":1569099990517}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"s79OyL4VxcJC","colab_type":"code","outputId":"fd32a5ff-4141-4dc0-b58a-80868bcef490","executionInfo":{"status":"ok","timestamp":1569806201851,"user_tz":180,"elapsed":7275,"user":{"displayName":"joao camargo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqUqSxVOfnmyReIORrytmeNEuXs8NkBKLMAOE9kQ=s64","userId":"07451748302293939850"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip install torch torchvision\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MjomI4580atc","colab_type":"code","colab":{}},"source":["import torch\n","import matplotlib.pyplot as plt \n","import numpy as np\n","import torch.nn.functional as F\n","from torch import nn\n","from torchvision import datasets, transforms, models"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuL5gNBesxVa","colab_type":"code","outputId":"ea6a04ca-79f3-438c-d1bf-f8f69cd26ecd","executionInfo":{"status":"ok","timestamp":1569806203407,"user_tz":180,"elapsed":8799,"user":{"displayName":"joao camargo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqUqSxVOfnmyReIORrytmeNEuXs8NkBKLMAOE9kQ=s64","userId":"07451748302293939850"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","#device = \"cpu\"\n","print(device)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WhXUr47UARD7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"e05ee96e-cc26-4083-ae94-0e76e7f30229","executionInfo":{"status":"ok","timestamp":1569806215273,"user_tz":180,"elapsed":20644,"user":{"displayName":"joao camargo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqUqSxVOfnmyReIORrytmeNEuXs8NkBKLMAOE9kQ=s64","userId":"07451748302293939850"}}},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=1ee960df19e1789cdc390bd9be9c5a5b472ea97d1ef22a74e17db47ec75e2a0a\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.8 GB  | Proc size: 266.3 MB\n","GPU RAM Free: 11430MB | Used: 11MB | Util   0% | Total 11441MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YQaSRT4wQMLR","colab_type":"text"},"source":["# Importar dataset"]},{"cell_type":"code","metadata":{"id":"O5JWXDIdQPEM","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OK3NOUlIQQFa","colab_type":"code","colab":{}},"source":["#!ls '/content/drive/My Drive/Colab_Notebooks/Resources/trabalho_deep1'\n","pathXRayImages =  '/content/drive/My Drive/Colab_Notebooks/Resources/trabalho_deep1'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhK_UdMhQ-id","colab_type":"code","colab":{}},"source":["#!ls '/content/drive/My Drive/Colab_Notebooks/Resources/trabalho_deep1/train/NORMAL'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"24sOAnYlbROv","colab_type":"code","colab":{}},"source":["from PIL import Image\n","\n","std = []\n","\n","PATHTrain = pathXRayImages + '/train/'\n","PATHTest = pathXRayImages + '/test/'\n","PATHVal = pathXRayImages + '/val/'\n","#files = os.listdir(PATH)\n","#x = np.array([np.array(Image.open(PATH + fname)) for fname in files])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"grbvYSr_by0E","colab_type":"code","colab":{}},"source":["#for fname in files:\n","#  x = np.array([np.array(Image.open(PATH + fname))])\n","#  print(x.shape,fname)\n","  \n","                \n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OY_pFbFzbTkV","colab_type":"code","colab":{}},"source":["#print(count(x[0].shape))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDBJgdjLDIx9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WPCLPuzARn_l","colab_type":"code","colab":{}},"source":["IGNORAR ISSO \n","#x = np.array([np.array(Image.open(PATH + fname)) for fname in files])\n","for image in np.array([np.array(Image.open(PATH + fname)) for fname in files]):  \n","  if len(image.shape) ==2:    \n","    c = 0  \n","    #r_std = image[:,:,c].flatten()\n","    b_std = image[:,c].flatten()\n","    c+=1\n","    #g_std = image[:,:,c].flatten()\n","    w_std = image[:,c].flatten()\n","    c+=1\n","    #b_std = image[:,:,c].flatten()\n","    #b_std = image[:,c].flatten()\n","    #std.append(np.array([r_std,g_std,b_std]))\n","    std.append(np.array([b_std,w_std]))\n","  else:\n","    print(image.shape,len(image.shape))\n","    plt.imshow(image)\n","\n","np_std = np.array(std)\n","\n","b_channel = np_std[0].flatten()\n","w_channel = np_std[1].flatten()\n","\n","#r_channel = np_std[:,0].flatten()\n","#g_channel = np_std[:,1].flatten()\n","#b_channel = np_std[:,2].flatten()\n","\n","b_norm = np.std(b_channel) / 255\n","w_norm = np.std(w_channel) / 255\n","imgs_std = np.array([b_norm,w_norm])\n","#r_norm = np.std(r_channel) / 255\n","#g_norm = np.std(g_channel) / 255\n","#b_norm = np.std(b_channel) / 255\n","#imgs_std = np.array([r_norm,g_norm,b_norm])\n","print(imgs_std)\n","\n","#[0.08519155 0.12588292]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCrhMHwz2Iqw","colab_type":"code","colab":{}},"source":["transform_train = transforms.Compose([transforms.Resize((224,224)),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      #transforms.RandomRotation(10),\n","                                      transforms.RandomAffine(0,shear=10,scale=(0.8,1.2)),\n","                                      #transforms.ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n","\n","\n","transform = transforms.Compose([transforms.Resize((224,224)),\n","                                transforms.ToTensor(),\n","                                 transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n","\n","training_dataset = datasets.ImageFolder(root=PATHTrain,transform=transform_train)\n","validation_dataset = datasets.ImageFolder(root=PATHVal,transform=transform)\n","training_loader = torch.utils.data.DataLoader(dataset=training_dataset,batch_size=40,shuffle=True)\n","validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=40,shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5UxHCNvW3Kio","colab_type":"code","colab":{}},"source":["def im_convert(tensor):\n","  image = tensor.cpu().clone().detach().numpy()\n","  image = image.transpose(1,2,0)\n","  #print(image.shape)\n","  #retirar a normalização\n","  image = image * np.array((0.5,0.5,0.5)) + np.array((0.5,0.5,0.5))\n","  image = image.clip(0,1)\n","  return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdexpx4QK79b","colab_type":"code","colab":{}},"source":["def getitem(self, item): \n","  image, label = self.imgs[item] \n","  image = Image.open(image) \n","  img = transform(image) \n","  return img, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_GhrjBa67m92","colab_type":"code","colab":{}},"source":["classes = (\n","    'NORMAL','PNEUMONIA'\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5mcOIJc3uTH","colab_type":"code","colab":{}},"source":["dataiter = iter(training_loader)\n","images,labels = dataiter.next()\n","\n","fig = plt.figure(figsize=(10,10))\n","\n","for idx in np.arange(25):\n","  ax = fig.add_subplot(5,5,idx+1,xticks=[],yticks=[])\n","  plt.imshow(im_convert(images[idx]))\n","  ax.set_title(classes[labels[idx].item()])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIXtoU3k6deA","colab_type":"code","colab":{}},"source":["class LeNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(3,16,3,1,padding=1)\n","    self.conv2 = nn.Conv2d(16,32,3,1,padding=1)\n","    self.conv3 = nn.Conv2d(32,64,3,1,padding=1)\n","    self.fc1 = nn.Linear(4*4*64,500)\n","    self.dropout1 = nn.Dropout(0.5) #colocar dropout pra evirar overfitting (colocar onde há bastante parametros)\n","    self.fc2 = nn.Linear(500,100)  #o segundo numero é o numero de classes  \n","  def forward(self,x):\n","    x = F.relu(self.conv1(x))\n","    x = F.max_pool2d(x,2,2)\n","    x = F.relu(self.conv2(x))\n","    x = F.max_pool2d(x,2,2)\n","    x = F.relu(self.conv3(x))\n","    x = F.max_pool2d(x,2,2)\n","    x = x.view(-1,4*4*64)\n","    x = F.relu(self.fc1(x))\n","    x = self.dropout1(x)#colocar dropout pra evirar overfitting (colocar onde há bastante parametros)\n","    x = self.fc2(x)\n","    return x\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZuFZitw9KeQ","colab_type":"code","colab":{}},"source":["#model = LeNet().to(device)\n","#model\n","\n","\n","model = models.resnet50()\n","model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2pxdAi7kQ9sA","colab_type":"code","colab":{}},"source":["for param in model.parameters():\n","    param.requires_grad = False\n","\n","model.fc = nn.Linear(2048, 2)  \n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_WrVuPHSwkv","colab_type":"code","colab":{}},"source":["#mudando apenas para duas classes\n","#n_inputs = model.classifier['fc'].in_features\n","#last_layer = nn.Linear(n_inputs,len(classes))\n","#model.classifier[6] = last_layer\n","model.to(device)\n","print(model)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EMApUQ4k-ejZ","colab_type":"code","colab":{}},"source":["import time\n","start_time = time.time()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n","\n","print('levou {} segundos '.format(time.time() - start_time))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcskvLWw-n6D","colab_type":"code","colab":{}},"source":["CUDA_LAUNCH_BLOCKING=1\n","\n","import time\n","start_time = time.time()\n","\n","\n","\n","epochs = 25\n","\n","running_loss_history=[]\n","running_corrects_history=[]\n","\n","val_running_loss_history=[]\n","val_running_corrects_history=[]\n","\n","\n","for e in range(epochs):\n","  running_loss = 0.0\n","  running_corrects = 0.0\n","  val_running_loss = 0.0\n","  val_running_corrects = 0.0\n","  \n","  for inputs, labels in training_loader:\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","    outputs = model(inputs)\n","    loss = criterion(outputs,labels)\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    _,preds = torch.max(outputs,1)    \n","    running_loss += loss.item()\n","    running_corrects+= torch.sum(preds == labels.data)    \n","    \n","  else:\n","    with torch.no_grad():\n","      for val_inputs, val_labels in validation_loader:\n","        val_inputs = val_inputs.to(device)\n","        val_labels = val_labels.to(device)\n","        val_outputs = model(val_inputs)\n","        val_loss = criterion(val_outputs,val_labels)        \n","        \n","        _,val_preds = torch.max(val_outputs,1)\n","        val_running_loss += val_loss.item()\n","        val_running_corrects+= torch.sum(val_preds == val_labels.data)  \n","      \n","    epoch_loss = running_loss/len(training_loader.dataset)\n","    #epoch_loss = calcula o loss function atual\n","    epoch_acc = running_corrects.float()/len(training_loader.dataset)\n","    #epoch_acc = pega a quantiade de acertos que teve em relacao ao total e seta a porcentagem de acertos\n","    running_loss_history.append(epoch_loss)\n","    running_corrects_history.append(epoch_acc)\n","    \n","    val_epoch_loss = val_running_loss/len(validation_loader.dataset)\n","    #epoch_loss = calcula o loss function atual\n","    val_epoch_acc = val_running_corrects.float()/len(validation_loader.dataset)\n","    #epoch_acc = pega a quantiade de acertos que teve em relacao ao total e seta a porcentagem de acertos\n","    val_running_loss_history.append(val_epoch_loss)    \n","    val_running_corrects_history.append(val_epoch_acc)    \n","    \n","    print('epoch: ',str(e+1))\n","    print('training_loss: {:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))\n","    print('validation_loss: {:.4f}, validation acc {:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))\n","    #print('difference between loss:', val_epoch_loss-epoch_loss)\n","\n","    \n","print('levou {} segundos '.format(time.time() - start_time))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kH8EgTg1IplK","colab_type":"code","colab":{}},"source":["#training_loss: 0.8267,71.0100\n","#validation_loss: 0.7724, validation acc 73.7500\n","#difference between loss: -0.0543566477298737"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7x6rIuY2_nzO","colab_type":"code","colab":{}},"source":["plt.plot(running_loss_history,label='training loss')\n","plt.plot(val_running_loss_history,label='validation loss')\n","plt.legend()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TK7ILGRDEHk","colab_type":"code","colab":{}},"source":["plt.plot(running_corrects_history,label='qnt de corretas  no treino',color=\"black\")\n","plt.plot(val_running_corrects_history,label='qnt de corretas na validacao', color='red')\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3b1-HaIOBy7K","colab_type":"code","colab":{}},"source":["dataiter = iter(validation_loader)\n","images,labels = dataiter.next()\n","images = images.to(device)\n","labels = labels.to(device)\n","model.eval()\n","output = model(images)\n","_,preds = torch.max(output,1)\n","\n","fig = plt.figure(figsize=(25,25))\n","\n","acertos = 0\n","erros = 0\n","\n","for idx in np.arange(len(images)):\n","  ax = fig.add_subplot(10,10,idx+1,xticks=[],yticks=[])\n","  plt.imshow(im_convert(images[idx]))  \n","  if preds[idx]==labels[idx]:\n","    acertos = acertos +1\n","  else:\n","    erros = erros +1\n","  ax.set_title(\"{} ({})\".format(str(classes[preds[idx].item()]),str(classes[labels[idx].item()])),color=('green' if preds[idx]==labels[idx] else \"red\"))\n","  \n","print('acertos: {} \\nerros:{}'.format(acertos,erros))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HXUhuuz2Euwc","colab_type":"code","colab":{}},"source":["33‹‹‹"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WNezg_BvqJW","colab_type":"code","colab":{}},"source":["class_correct = list(0. for i in range(100))\n","class_total = list(0. for i in range(100))\n","with torch.no_grad():\n","    for data in dataiter:\n","        images, labels = data\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","\n","for i in range(100):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFsUyQrOxUwH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vfAFabNn5-_4","colab_type":"text"},"source":["#LINKS PARA AJUDAR\n"]},{"cell_type":"markdown","metadata":{"id":"F6bf0hOQ6fO1","colab_type":"text"},"source":["https://medium.com/unit8-machine-learning-publication/detecting-pneumonia-on-x-ray-images-covnets-and-transfer-learning-6d94b58c6657\n","\n","https://www.kaggle.com/goelrajat/prediciting-pneumonia-from-chest-xray/code\n","\n","https://www.kaggle.com/aakashnain/beating-everything-with-depthwise-convolution\n","\n","https://github.com/naity/pneumonia/blob/master/Pneumonia-colab.ipynb\n","\n","https://becominghuman.ai/detecting-pneumonia-with-deep-learning-3cf49b640c14\n","\n","https://github.com/rslim087a/PyTorch-for-Deep-Learning-and-Computer-Vision-Course-All-Codes-/blob/master/PyTorch%20for%20Deep%20Learning%20and%20Computer%20Vision%20Course%20(All%20Codes)/Transfer_Learning.ipynb\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ldu6lu-T6A1Y","colab_type":"code","colab":{}},"source":["\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3ugt8SV6hYj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}