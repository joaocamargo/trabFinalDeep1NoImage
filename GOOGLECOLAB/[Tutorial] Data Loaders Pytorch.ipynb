{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In summary, the neural network training pipeline in Pytorch is as follows: \n",
    "\n",
    "### 1. Data definition\n",
    "* Dataset: create a Dataset class (torch.utils.data.Dataset) designed to return a single instance when indexed. \n",
    "* DataLoader: create a DataLoader class (torch.utils.data.DataLoader) to sample instance batches using parallel workers. \n",
    "\n",
    "### 2. Model Definition\n",
    "* Model: build a neural network architecture using Module classes (torch.nn.Module).\n",
    "* Loss: a loss function is also a PyTorch module, and hence you can create your own loss function, or use a default implementation from the framework (e.g., torch.nn.CrossEntropyLoss). More details at: https://pytorch.org/docs/stable/nn.html#loss-functions.\n",
    "\n",
    "### 3. Training\n",
    "* Hyper-parameter tuning: try several hyper-parameter combinations in order to find what works best. \n",
    "* Training: train your models during several epochs. Use some early stopping criteria (e.g., stop training if validation accuracy stop increasing in 5 epochs)\n",
    "* Evaluation: evaluate your best model on test set.\n",
    "\n",
    "**Note**: there are a plethora of standard datasets and neural net models at: https://pytorch.org/docs/stable/torchvision/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, let's get started by importing useful stuff, and defining cool image plot functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(sample_img, sample_label):\n",
    "    plt.imshow(sample_img, cmap='gray', )\n",
    "    _ = plt.title(f'Label: {sample_label}')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "def plot_multiple_images(images, labels, n=6):\n",
    "    fig, ax = plt.subplots(1,n)\n",
    "    for i, (img, label) in enumerate(zip(images, labels)):\n",
    "        ax[i].imshow(img, )\n",
    "        ax[i].set_title(f'Label: {label}')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data definition\n",
    "\n",
    "## 1.1 Using a pre-defined torchvision dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST('mnist/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img, sample_label = mnist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_image(sample_img, sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cifar = datasets.CIFAR10('cifar/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img, sample_label = cifar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_image(sample_img, sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: SVHN (house number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svhn = datasets.SVHN('svhn/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = [svhn[i] for i in range(6)]\n",
    "sample_images, sample_labels = zip(*sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_images(sample_images, sample_labels, n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Using your own images \n",
    "\n",
    "The easier way to use your own images in PyTorch dataset is by using the ImageFolder class (torchvision.datasets.ImageFolder).\n",
    "\n",
    "ImageFolder datasets are expecting a path to your images, that should organized as follows:\n",
    "\n",
    "* root/dog/xxx.png\n",
    "* root/dog/xxy.png\n",
    "* root/dog/xxz.png\n",
    "\n",
    "* root/cat/123.png\n",
    "* root/cat/nsdf3.png\n",
    "* root/cat/asd932_.png\n",
    "\n",
    "*I.e.,*each folder inside the provided root directory are going to be used as classes. The dataset itself is going to define the number of classes based on the number of folders that contain images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example using the reduced RPS (Rock Paper Scissor) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://github.com/YoussefAch/RPS-classification-using-PyTorch/blob/master/RPS.tar.gz\n",
    "! tar xf RPS.tar.gz\n",
    "! ls -l RPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps = datasets.ImageFolder('RPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = [rps[i] for i in range(3)]\n",
    "sample_images, sample_labels = zip(*sample_data)\n",
    "plot_multiple_images(sample_images, sample_labels, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Building your customized dataset\n",
    "\n",
    "Keep in mind:\n",
    "* You have to override: `__init__`, `__getitem__` and `__len__` functions.\n",
    "* Your class has to handle train / val / test splits\n",
    "* You have to apply transforms by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "\n",
    "def load_image(path):\n",
    "    from PIL import Image\n",
    "    img = Image.open(path)\n",
    "    return img.convert('RGB')\n",
    "    \n",
    "    \n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.images = glob(f'{path}/*/*.jpg')\n",
    "        self.classes_str = [x.split('/')[-2] for x in self.images]\n",
    "        self.class_set = sorted(list(set(self.classes_str)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        label_str = self.classes_str[idx]\n",
    "        label_int = self.class_set.index(label_str)\n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label_int, label_str\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset('RPS/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img, sample_label, sample_label_str = dataset[60]\n",
    "plot_image(sample_img.permute(1, 2, 0), f'{sample_label} - {sample_label_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If your dataset is static and fits entirely into the RAM memory, you can load the whole dataset once, convert it to Tensor, and then use the class TensorDataset (`torch.utils.data.TensorDataset`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use a DataLoader to sample batches using your dataset\n",
    "\n",
    "DataLoaders can handle every type of `torch.utils.data.Dataset` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=6, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels, labels_str in train_loader:\n",
    "    plot_multiple_images(images.permute(0, 2, 3, 1), labels, n=6)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fashion)",
   "language": "python",
   "name": "fashion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
